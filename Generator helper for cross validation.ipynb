{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39d1e9c",
   "metadata": {},
   "source": [
    "This notebook shows an efficient way to create a grid search cross-validation training set for time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613d59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd532e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490497b2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdbcaff",
   "metadata": {},
   "source": [
    "Pick FAANG tech company as my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c88e1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">META</th>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>128.990005</td>\n",
       "      <td>137.509995</td>\n",
       "      <td>128.559998</td>\n",
       "      <td>135.679993</td>\n",
       "      <td>135.536194</td>\n",
       "      <td>28146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>134.690002</td>\n",
       "      <td>137.169998</td>\n",
       "      <td>131.119995</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>131.600372</td>\n",
       "      <td>22717900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>134.009995</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>133.750000</td>\n",
       "      <td>137.949997</td>\n",
       "      <td>137.803787</td>\n",
       "      <td>29002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>137.559998</td>\n",
       "      <td>138.869995</td>\n",
       "      <td>135.910004</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>137.903687</td>\n",
       "      <td>20089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>139.889999</td>\n",
       "      <td>143.139999</td>\n",
       "      <td>139.539993</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>142.378937</td>\n",
       "      <td>26263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">GOOG</th>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>142.130005</td>\n",
       "      <td>143.250000</td>\n",
       "      <td>142.054993</td>\n",
       "      <td>142.720001</td>\n",
       "      <td>142.720001</td>\n",
       "      <td>18494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>142.979996</td>\n",
       "      <td>143.945007</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>142.820007</td>\n",
       "      <td>142.820007</td>\n",
       "      <td>11170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>142.830002</td>\n",
       "      <td>143.320007</td>\n",
       "      <td>141.050995</td>\n",
       "      <td>141.440002</td>\n",
       "      <td>141.440002</td>\n",
       "      <td>17288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>141.850006</td>\n",
       "      <td>142.270004</td>\n",
       "      <td>140.828003</td>\n",
       "      <td>141.279999</td>\n",
       "      <td>141.279999</td>\n",
       "      <td>12192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>140.679993</td>\n",
       "      <td>141.434998</td>\n",
       "      <td>139.899994</td>\n",
       "      <td>140.929993</td>\n",
       "      <td>140.929993</td>\n",
       "      <td>14872700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6290 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open        High         Low       Close   Adj Close  \\\n",
       "Ticker Date                                                                     \n",
       "META   2019-01-02  128.990005  137.509995  128.559998  135.679993  135.536194   \n",
       "       2019-01-03  134.690002  137.169998  131.119995  131.740005  131.600372   \n",
       "       2019-01-04  134.009995  138.000000  133.750000  137.949997  137.803787   \n",
       "       2019-01-07  137.559998  138.869995  135.910004  138.050003  137.903687   \n",
       "       2019-01-08  139.889999  143.139999  139.539993  142.529999  142.378937   \n",
       "...                       ...         ...         ...         ...         ...   \n",
       "GOOG   2023-12-22  142.130005  143.250000  142.054993  142.720001  142.720001   \n",
       "       2023-12-26  142.979996  143.945007  142.500000  142.820007  142.820007   \n",
       "       2023-12-27  142.830002  143.320007  141.050995  141.440002  141.440002   \n",
       "       2023-12-28  141.850006  142.270004  140.828003  141.279999  141.279999   \n",
       "       2023-12-29  140.679993  141.434998  139.899994  140.929993  140.929993   \n",
       "\n",
       "                     Volume  \n",
       "Ticker Date                  \n",
       "META   2019-01-02  28146200  \n",
       "       2019-01-03  22717900  \n",
       "       2019-01-04  29002100  \n",
       "       2019-01-07  20089300  \n",
       "       2019-01-08  26263800  \n",
       "...                     ...  \n",
       "GOOG   2023-12-22  18494700  \n",
       "       2023-12-26  11170100  \n",
       "       2023-12-27  17288400  \n",
       "       2023-12-28  12192500  \n",
       "       2023-12-29  14872700  \n",
       "\n",
       "[6290 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = ['META', 'AMZN', 'AAPL', 'NFLX', 'GOOG']\n",
    "temp_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, '2019-01-01', '2023-12-31')\n",
    "    data['Ticker'] = ticker\n",
    "    temp_list.append(data)\n",
    "    \n",
    "temp = pd.concat(temp_list, keys = tickers, names=['Ticker', 'Date'])\n",
    "temp = temp.drop(['Ticker'], axis = 1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1b0675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "AAPL    1258\n",
       "AMZN    1258\n",
       "GOOG    1258\n",
       "META    1258\n",
       "NFLX    1258\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupby('Ticker').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300cdb6",
   "metadata": {},
   "source": [
    "To construct a generator for use with an sklearn model, you'll need to define a class for the Generator. The approach involves dividing the dataset into $n$ segments, where each test set follows sequentially. For instance, if you divide your dataset into 10 segments with a testing period of 20 days, the most recent test set will encompass the final 20 days of your dataset. The test set before that will cover the period from the 40th to the 20th last day, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f152276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesCV:\n",
    "    def __init__(self,test_size = 10,n_split = 10,train_size = 50, lag = 1):\n",
    "        self.test_size = test_size\n",
    "        self.n_split = n_split\n",
    "        self.lag = lag\n",
    "        self.train_size = train_size\n",
    "        \n",
    "        \n",
    "    def split(self, X: pd.DataFrame, y: np.ndarray = None, groups: np.ndarray = None):\n",
    "        date = X.index.get_level_values('Date').unique()  #Get the unique date listed from the dateset\n",
    "        date = date.sort_values(ascending = False) #Sort the date list in reverse order\n",
    "        sto = []\n",
    "        for i in range(self.n_split):\n",
    "            test_end_idx = i * self.n_split #calculate the end date from the test set\n",
    "            test_start_idx = test_end_idx + self.test_size\n",
    "            train_end_idx = test_start_idx + self.lag - 1\n",
    "            train_start_idx = train_end_idx + self.train_size\n",
    "            sto.append([test_end_idx, test_start_idx, train_end_idx, train_start_idx])\n",
    "\n",
    "            \n",
    "#Use the beginning date and ending date \n",
    "        dates_col = X.reset_index()[['Date']]\n",
    "        for i in sto:\n",
    "            train_idx = dates_col[(dates_col['Date'] > date[i[3]]) & (dates_col['Date'] <= date[i[2]])].index\n",
    "            test_idx = dates_col[(dates_col['Date'] > date[i[1]]) & (dates_col['Date'] <= date[i[0]])].index\n",
    "            \n",
    "            \n",
    "            yield train_idx, test_idx\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d06b2c",
   "metadata": {},
   "source": [
    "A quick test for the TimeSeriesCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "55d9e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date\n",
      "6264 2023-11-22\n",
      "6265 2023-11-24\n",
      "6266 2023-11-27\n",
      "6267 2023-11-28\n",
      "6268 2023-11-29\n",
      "           Date\n",
      "1238 2023-12-01\n",
      "1239 2023-12-04\n",
      "1240 2023-12-05\n",
      "1241 2023-12-06\n",
      "1242 2023-12-07\n",
      "           Date\n",
      "6254 2023-11-08\n",
      "6255 2023-11-09\n",
      "6256 2023-11-10\n",
      "6257 2023-11-13\n",
      "6258 2023-11-14\n",
      "           Date\n",
      "1228 2023-11-16\n",
      "1229 2023-11-17\n",
      "1230 2023-11-20\n",
      "1231 2023-11-21\n",
      "1232 2023-11-22\n",
      "           Date\n",
      "6244 2023-10-25\n",
      "6245 2023-10-26\n",
      "6246 2023-10-27\n",
      "6247 2023-10-30\n",
      "6248 2023-10-31\n",
      "           Date\n",
      "1218 2023-11-02\n",
      "1219 2023-11-03\n",
      "1220 2023-11-06\n",
      "1221 2023-11-07\n",
      "1222 2023-11-08\n",
      "           Date\n",
      "6234 2023-10-11\n",
      "6235 2023-10-12\n",
      "6236 2023-10-13\n",
      "6237 2023-10-16\n",
      "6238 2023-10-17\n",
      "           Date\n",
      "1208 2023-10-19\n",
      "1209 2023-10-20\n",
      "1210 2023-10-23\n",
      "1211 2023-10-24\n",
      "1212 2023-10-25\n",
      "           Date\n",
      "6224 2023-09-27\n",
      "6225 2023-09-28\n",
      "6226 2023-09-29\n",
      "6227 2023-10-02\n",
      "6228 2023-10-03\n",
      "           Date\n",
      "1198 2023-10-05\n",
      "1199 2023-10-06\n",
      "1200 2023-10-09\n",
      "1201 2023-10-10\n",
      "1202 2023-10-11\n",
      "           Date\n",
      "6214 2023-09-13\n",
      "6215 2023-09-14\n",
      "6216 2023-09-15\n",
      "6217 2023-09-18\n",
      "6218 2023-09-19\n",
      "           Date\n",
      "1188 2023-09-21\n",
      "1189 2023-09-22\n",
      "1190 2023-09-25\n",
      "1191 2023-09-26\n",
      "1192 2023-09-27\n",
      "           Date\n",
      "6204 2023-08-29\n",
      "6205 2023-08-30\n",
      "6206 2023-08-31\n",
      "6207 2023-09-01\n",
      "6208 2023-09-05\n",
      "           Date\n",
      "1178 2023-09-07\n",
      "1179 2023-09-08\n",
      "1180 2023-09-11\n",
      "1181 2023-09-12\n",
      "1182 2023-09-13\n",
      "           Date\n",
      "6194 2023-08-15\n",
      "6195 2023-08-16\n",
      "6196 2023-08-17\n",
      "6197 2023-08-18\n",
      "6198 2023-08-21\n",
      "           Date\n",
      "1168 2023-08-23\n",
      "1169 2023-08-24\n",
      "1170 2023-08-25\n",
      "1171 2023-08-28\n",
      "1172 2023-08-29\n",
      "           Date\n",
      "6184 2023-08-01\n",
      "6185 2023-08-02\n",
      "6186 2023-08-03\n",
      "6187 2023-08-04\n",
      "6188 2023-08-07\n",
      "           Date\n",
      "1158 2023-08-09\n",
      "1159 2023-08-10\n",
      "1160 2023-08-11\n",
      "1161 2023-08-14\n",
      "1162 2023-08-15\n",
      "           Date\n",
      "6174 2023-07-18\n",
      "6175 2023-07-19\n",
      "6176 2023-07-20\n",
      "6177 2023-07-21\n",
      "6178 2023-07-24\n",
      "           Date\n",
      "1148 2023-07-26\n",
      "1149 2023-07-27\n",
      "1150 2023-07-28\n",
      "1151 2023-07-31\n",
      "1152 2023-08-01\n"
     ]
    }
   ],
   "source": [
    "aa = TimeSeriesCV(test_size =20, n_split = 10, train_size = 50, lag = 2)\n",
    "dates_col = temp.reset_index()[['Date']]\n",
    "dates_col\n",
    "\n",
    "for i in aa.split(temp):\n",
    "    print(dates_col.iloc[i[0]].tail(5))\n",
    "    print(dates_col.iloc[i[1]].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ae2e4",
   "metadata": {},
   "source": [
    "Test passed. As you can see, there is a lag 2 between the training set and testing set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
